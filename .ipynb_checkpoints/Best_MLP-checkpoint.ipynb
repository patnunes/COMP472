{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best-MLP: a better performing Multi-Layered Perceptron found by performing grid search to Ô¨Ånd the best combination of hyper-parameters. For this, you need to experiment with the following parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. activation function: sigmoid, tanh, relu and identity \n",
    "2. network architectures of your choice: for eg 2 hidden layers with 30+50 nodes, 3 hidden layers with 10+10\n",
    "3. solver: Adam and stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space=[\n",
    "    { 'activation': ['logistic','tanh','relu','identity'], 'hidden_layer_sizes':[(30,50),(10,10,10)], 'solver':['adam','sgd']}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds1 = pd.read_csv(\"Assig1-Dataset/train_1.csv\", sep=\",\", header=None)\n",
    "testing_ds1 = pd.read_csv(\"Assig1-Dataset/test_with_label_1.csv\", sep=\",\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = training_ds1.drop(training_ds1.columns[-1],axis=1)\n",
    "training_targets = training_ds1[training_ds1.columns[-1]]\n",
    "\n",
    "testing_features = testing_ds1.drop(training_ds1.columns[-1],axis=1)\n",
    "testing_targets = testing_ds1[training_ds1.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=adam ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=adam, total=   5.4s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=adam ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=adam, total=   5.5s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=adam ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=adam, total=   5.3s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=adam ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=adam, total=   5.4s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=adam ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=adam, total=   5.4s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd ....\n",
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd, total=   2.3s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd ....\n",
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd, total=   2.2s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd ....\n",
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd, total=   2.2s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd ....\n",
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd, total=   2.2s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd ....\n",
      "[CV]  activation=logistic, hidden_layer_sizes=(30, 50), solver=sgd, total=   2.4s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam, total=   4.5s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam, total=   4.5s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam, total=   4.5s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam, total=   4.6s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=adam, total=   4.8s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd \n",
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd, total=   3.3s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd \n",
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd, total=   3.0s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd \n",
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd, total=   3.1s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd \n",
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd, total=   3.2s\n",
      "[CV] activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd \n",
      "[CV]  activation=logistic, hidden_layer_sizes=(10, 10, 10), solver=sgd, total=   2.9s\n",
      "[CV] activation=tanh, hidden_layer_sizes=(30, 50), solver=adam .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, hidden_layer_sizes=(30, 50), solver=adam, total=   5.5s\n",
      "[CV] activation=tanh, hidden_layer_sizes=(30, 50), solver=adam .......\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier() #Choose your classifier\n",
    "clf = GridSearchCV(mlp, parameter_space, verbose=2).fit(training_features, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_best_MLP = clf.predict(testing_features)\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) a plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_MLP_confusion_matrix = confusion_matrix(testing_targets, predicted_best_MLP)\n",
    "print(best_MLP_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)(d) the precision, recall, and f1-measure for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.60      0.75      0.67         4\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.75      0.75      0.75         4\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.33      1.00      0.50         3\n",
      "           9       0.67      0.50      0.57         4\n",
      "          10       0.25      0.67      0.36         3\n",
      "          11       1.00      0.75      0.86         4\n",
      "          12       0.50      1.00      0.67         3\n",
      "          13       0.30      0.75      0.43         4\n",
      "          14       0.30      1.00      0.46         3\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       1.00      0.67      0.80         3\n",
      "          17       0.23      0.75      0.35         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.50      0.33      0.40         3\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        80\n",
      "   macro avg       0.31      0.38      0.30        80\n",
      "weighted avg       0.35      0.42      0.34        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_MLP_classification_report = classification_report(testing_targets, predicted_base_MLP,output_dict=True)\n",
    "print(classification_report(testing_targets, predicted_base_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e) Writing to .csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './outputs/Base-MLP/Base-MLP-DS1.csv'\n",
    "\n",
    "\n",
    "with open(filename, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file) \n",
    "    base_MLP_results = np.arange(1, predicted_base_MLP.shape[0])\n",
    "    writer.writerow([\"Predicted Results:\"])\n",
    "    for i in zip(np.arange(1, predicted_base_MLP.shape[0]), predicted_base_MLP):\n",
    "        writer.writerow([i])\n",
    "    writer.writerow(\"\")\n",
    "\n",
    "with open(filename, 'a') as file:\n",
    "    writer = csv.writer(file)    \n",
    "    \n",
    "    df = pd.DataFrame(base_MLP_confusion_matrix)\n",
    "    df.to_csv(filename,index=False, header = False, mode = 'a')\n",
    "    writer.writerow(\"\")\n",
    "    \n",
    "with open(filename, 'a') as file:\n",
    "    writer = csv.writer(file)    \n",
    "    \n",
    "    df = pd.DataFrame(base_MLP_classification_report).transpose()\n",
    "    df.to_csv(filename, mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Dataset 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds2 = pd.read_csv(\"Assig1-Dataset/train_2.csv\", sep=\",\", header=None)\n",
    "testing_ds2 = pd.read_csv(\"Assig1-Dataset/test_with_label_2.csv\", sep=\",\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features2 = training_ds2.drop(training_ds2.columns[-1],axis=1)\n",
    "training_targets2 = training_ds2[training_ds2.columns[-1]]\n",
    "\n",
    "testing_features2 = testing_ds2.drop(training_ds2.columns[-1],axis=1)\n",
    "testing_targets2 = testing_ds2[training_ds2.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_MLP2 = MLPClassifier(hidden_layer_sizes= my_hidden_layer, activation=my_activation_function, solver=my_solver).fit(training_features2, training_targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_base_MLP2 = base_MLP2.predict(testing_features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) a plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 45   3   1   0   1   2   0   0   1   2]\n",
      " [  3 119   0   1   0   1   0   0   1   0]\n",
      " [  0   0   6   0   0   1   0   0   7   1]\n",
      " [  2   2   0   9   0   2   0   0   0   0]\n",
      " [  4   1   0   0  29   2   0   0   3  11]\n",
      " [  0   0   0   0   1  50   0   0   0   4]\n",
      " [  2   4   1   0   1   0   5   0   1   1]\n",
      " [  0   0   0   0   0   0   0  15   0   0]\n",
      " [  1   1   0   0   0   0   0   0  44   4]\n",
      " [  2   0   0   0   9   5   0   0   1 108]]\n"
     ]
    }
   ],
   "source": [
    "base_MLP_confusion_matrix2 = confusion_matrix(testing_targets2, predicted_base_MLP2)\n",
    "print(base_MLP_confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)(d) the precision, recall, and f1-measure for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        55\n",
      "           1       0.92      0.95      0.93       125\n",
      "           2       0.75      0.40      0.52        15\n",
      "           3       0.90      0.60      0.72        15\n",
      "           4       0.71      0.58      0.64        50\n",
      "           5       0.79      0.91      0.85        55\n",
      "           6       1.00      0.33      0.50        15\n",
      "           7       1.00      1.00      1.00        15\n",
      "           8       0.76      0.88      0.81        50\n",
      "           9       0.82      0.86      0.84       125\n",
      "\n",
      "    accuracy                           0.83       520\n",
      "   macro avg       0.84      0.73      0.76       520\n",
      "weighted avg       0.83      0.83      0.82       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_MLP_classification_report2 = classification_report(testing_targets2, predicted_base_MLP2, output_dict=True)\n",
    "print(classification_report(testing_targets2, predicted_base_MLP2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e) Writing to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = './outputs/Base-MLP/Base-MLP-DS2.csv'\n",
    "\n",
    "\n",
    "with open(filename2, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file) \n",
    "    base_MLP_results2 = np.arange(1, predicted_base_MLP2.shape[0])\n",
    "    writer.writerow([\"Predicted Results:\"])\n",
    "    for i in zip(np.arange(1, predicted_base_MLP2.shape[0]), predicted_base_MLP2):\n",
    "        writer.writerow([i])\n",
    "    writer.writerow(\"\")\n",
    "\n",
    "with open(filename2, 'a') as file:\n",
    "    writer = csv.writer(file)    \n",
    "    \n",
    "    df = pd.DataFrame(base_MLP_confusion_matrix2)\n",
    "    df.to_csv(filename2,index=False, header = False, mode = 'a')\n",
    "    writer.writerow(\"\")\n",
    "    \n",
    "with open(filename2, 'a') as file:\n",
    "    writer = csv.writer(file)    \n",
    "    \n",
    "    df = pd.DataFrame(base_MLP_classification_report2).transpose()\n",
    "    df.to_csv(filename2, mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
